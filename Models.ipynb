{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c53fa4-2b62-4bda-86fa-bfb2f692b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5923602b-9986-4997-a90e-6700710cb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "features_to_log = ['lake_elevation_m', 'lake_totalarea_ha', 'lake_perimeter_m', 'lake_shorelinedevfactor', 'lake_mix_layer_temperature', 'lake_mix_layer_temperature_min', 'lake_mix_layer_temperature_max', 'lake_mix_layer_depth', 'lake_mix_layer_depth_min', 'lake_mix_layer_depth_max', 'total_precipitation_sum', 'total_precipitation_min', 'total_precipitation_max']\n",
    "\n",
    "\n",
    "def np_RMSE(vec1,vec2, key):\n",
    "    #Exponentiate outputs if logged\n",
    "    if (key in features_to_log):\n",
    "        vec1 = np.vectorize(lambda x: math.exp(x)-1)(vec1)\n",
    "        vec2 = np.vectorize(lambda x: math.exp(x)-1)(vec2)\n",
    "    return np.sqrt(np.mean((vec1-vec2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532d2545-6871-433f-95b6-1a34e16ff321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset block is 1 reduction method and 1 parameter\n",
    "#Model block is \n",
    "def test_model(model_block, dataset_block, par):\n",
    "    model = model_block['model']\n",
    "    space_norm_RMSE = np_RMSE(model.predict(dataset_block[\"space_test\"][par][\"independent\"]),dataset_block[\"space_test\"][par][\"dependent\"], par)/(dataset_block[\"space_test\"][par][\"dependent\"].mean())\n",
    "    time_norm_RMSE = np_RMSE(model.predict(dataset_block[\"time_test\"][par][\"independent\"]),dataset_block[\"time_test\"][par][\"dependent\"], par)/(dataset_block[\"time_test\"][par][\"dependent\"].mean())\n",
    "    model_block['space_norm_RMSE'] = space_norm_RMSE\n",
    "    model_block['time_norm_RMSE'] = time_norm_RMSE\n",
    "    return model_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abddd3c-9eec-4da4-aaaf-3f2b6a5bc3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model_ffn(model_block, dataset_block, par):\n",
    "    model = model_block['model']\n",
    "    space_test_torch_ind = torch.from_numpy(dataset_block[\"space_test\"][par][\"independent\"].astype('float32'))\n",
    "    time_test_torch_ind = torch.from_numpy(dataset_block[\"time_test\"][par][\"independent\"].astype('float32'))\n",
    "    space_norm_RMSE = np_RMSE(model.predict(space_test_torch_ind).view().squeeze(),dataset_block[\"space_test\"][par][\"dependent\"], par)/(dataset_block[\"space_test\"][par][\"dependent\"].mean())\n",
    "    time_norm_RMSE = np_RMSE(model.predict(time_test_torch_ind).view().squeeze(),dataset_block[\"time_test\"][par][\"dependent\"], par)/(dataset_block[\"time_test\"][par][\"dependent\"].mean())\n",
    "    model_block['space_norm_RMSE'] = space_norm_RMSE\n",
    "    model_block['time_norm_RMSE'] = time_norm_RMSE\n",
    "    return model_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d5840-8a09-451a-9ac4-f32f59c41fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7314e33-f700-46ee-85c7-e91b3ffc0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d9c9725-c380-4dd7-aea4-1d19ee05d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "def train_dummy(formatted_dataset):\n",
    "    dummy_models = {}\n",
    "    for key,obs_set in formatted_dataset.items():\n",
    "\n",
    "        reg = DummyRegressor(strategy='mean').fit(obs_set[\"X_train\"], obs_set[\"y_train\"])\n",
    "        dummy_models[key] = {\"model\":reg, \"score\":reg.score(obs_set[\"X_test\"], obs_set[\"y_test\"]), \"RMSE\":np_RMSE(reg.predict(obs_set[\"X_test\"]),obs_set[\"y_test\"], key)}\n",
    "        dummy_models[key]['norm_RMSE']=dummy_models[key]['RMSE']/(obs_set[\"y_test\"].mean())\n",
    "    return dummy_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d3b2d-cc19-404c-8597-3f71dbafb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf514a51-6455-41d5-925f-c14c7eba5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_RF(formatted_dataset, params):\n",
    "    RF_models = {}\n",
    "    for key,obs_set in formatted_dataset.items():\n",
    "        X = obs_set[\"X_train\"]\n",
    "        y = obs_set[\"y_train\"]\n",
    "        \n",
    "        rf = RandomForestRegressor() #GRADIENT BOOSTING TREE AND RANDOM FOREST ARE DIFFERENT\n",
    "        crf = GridSearchCV(rf,params, verbose = 1)\n",
    "        crf.fit(X,y)\n",
    "        \n",
    "        best_model = crf.best_estimator_\n",
    "        \n",
    "        RF_models[key] = {\"gridsearch\": crf, \"model\":best_model, \"params\": crf.get_params(), \"score\":crf.score(obs_set[\"X_test\"], obs_set[\"y_test\"]), \"RMSE\":np_RMSE(crf.predict(obs_set[\"X_test\"]),obs_set[\"y_test\"], key)}\n",
    "        RF_models[key]['norm_RMSE']=RF_models[key]['RMSE']/(obs_set[\"y_test\"].mean())\n",
    "    return RF_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48301c06-2f40-4d6a-8c3b-f9ac5a287565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, ensemble\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_SVR(formatted_dataset, params):\n",
    "    SVR_models = {}\n",
    "    for key,obs_set in formatted_dataset.items():\n",
    "        X = obs_set[\"X_train\"]\n",
    "        y = obs_set[\"y_train\"]\n",
    "        \n",
    "        rf = make_pipeline(StandardScaler(), SVR()) \n",
    "        crf = GridSearchCV(rf,params, verbose = 1)\n",
    "        crf.fit(X,y)\n",
    "        \n",
    "        best_model = crf.best_estimator_\n",
    "        \n",
    "        SVR_models[key] = {\"gridsearch\": crf, \"model\":best_model, \"params\": crf.get_params(), \"score\":crf.score(obs_set[\"X_test\"], obs_set[\"y_test\"]), \"RMSE\":np_RMSE(crf.predict(obs_set[\"X_test\"]),obs_set[\"y_test\"], key)}\n",
    "        SVR_models[key]['norm_RMSE']=SVR_models[key]['RMSE']/(obs_set[\"y_test\"].mean())\n",
    "    return SVR_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94ebbb9-c870-4788-a435-f2f26528b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "def train_KNN(formatted_dataset, params):\n",
    "    KNN_models = {}\n",
    "    for key,obs_set in formatted_dataset.items():\n",
    "        X = obs_set[\"X_train\"]\n",
    "        y = obs_set[\"y_train\"]\n",
    "        rf = KNeighborsRegressor() #GRADIENT BOOSTING TREE AND RANDOM FOREST ARE DIFFERENT\n",
    "        crf = GridSearchCV(rf,params, verbose = 1)\n",
    "        crf.fit(X,y)\n",
    "        best_model = crf.best_estimator_\n",
    "        KNN_models[key] = {\"gridsearch\": crf, \"model\":best_model, \"params\": crf.get_params(), \"score\":crf.score(obs_set[\"X_test\"], obs_set[\"y_test\"]), \"RMSE\":np_RMSE(crf.predict(obs_set[\"X_test\"]),obs_set[\"y_test\"], key)}\n",
    "        KNN_models[key]['norm_RMSE']=KNN_models[key]['RMSE']/(obs_set[\"y_test\"].mean())\n",
    "    return KNN_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded73cda-7413-4aaa-a0f5-0fcddce3f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "def train_Linear(formatted_dataset):\n",
    "    linear_models = {}\n",
    "    for key,obs_set in formatted_dataset.items():\n",
    "        X = obs_set[\"X_train\"]\n",
    "        y = obs_set[\"y_train\"]\n",
    "        reg = linear_model.LinearRegression().fit(X, y)\n",
    "        linear_models[key] = {\"model\":reg, \"score\":reg.score(obs_set[\"X_test\"], obs_set[\"y_test\"]), \"RMSE\":np_RMSE(reg.predict(obs_set[\"X_test\"]),obs_set[\"y_test\"], key)}\n",
    "        linear_models[key]['norm_RMSE']=linear_models[key]['RMSE']/(obs_set[\"y_test\"].mean())\n",
    "    return linear_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4098b-acdf-473e-be47-a9714ccc804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079a5a4b-f731-405f-a1b7-a960b6626c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class predictor_RELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(predictor_RELU, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(35,78)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc2 = nn.Linear(78,30)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.fc3 = nn.Linear(30,1)\n",
    "        #To ensure can inverse sig later\n",
    "\n",
    "    def forward(self, input, **kwargs):\n",
    "        return self.fc3(self.dropout2(self.act2(self.fc2(self.dropout(self.act(self.fc1(input)))))))\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "learning_rate = 1e-5 #Learning rate of 1e-5 doesnt even work this is so finnicky\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f5b71a9-d296-40bd-bb2b-c2ace0d90360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNet\n",
    "\n",
    "class ScoredNeuralNet(NeuralNet): #Subclass of wrapper from skorch with score\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ScoredNeuralNet, self).__init__(**kwargs)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return r2_score(self.predict(X),y)\n",
    "\n",
    "def train_FFN_RELU(dataset, params): #Add parameters later (Try higher learning rate)\n",
    "    ffn_models = {}\n",
    "    for key,obs_set in dataset.items():\n",
    "        model = ScoredNeuralNet(module = predictor_RELU, criterion = nn.MSELoss(), lr = 1e-4,  max_epochs = 60, optimizer = torch.optim.SGD, iterator_train__shuffle=True) \n",
    "        crf = GridSearchCV(model, params, refit = True, cv=5, verbose=3)#Change to 5 later, this is just for testing rn\n",
    "\n",
    "        \n",
    "        crf.fit(dataset[key][\"X_train\"].astype('float32'), np.expand_dims(dataset[key][\"y_train\"], axis = 1).astype('float32'))\n",
    "    \n",
    "        best_model = crf.best_estimator_\n",
    "        ffn_models[key]={\"gridsearch\":crf,\"model\":best_model,\"loss\":best_model.score(dataset[key][\"X_test\"].astype('float32'),dataset[key][\"y_test\"].astype('float32')), \"RMSE\":np_RMSE(best_model.predict(dataset[key][\"X_test\"].astype('float32')),dataset[key][\"y_test\"].astype('float32').squeeze(), key)}\n",
    "        ffn_models[key]['norm_RMSE']=ffn_models[key]['RMSE']/(obs_set[\"y_test\"].mean())\n",
    "    return ffn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ad3ce8-95a0-4d7e-ab4a-6e44967ca14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae696f2-f56e-4732-8d51-e52f77b46bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db283075-d214-4a71-ac5c-e93162b68759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# read data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def train_XG_boost(dataset, params):\n",
    "    XG_boost_models = {}\n",
    "    for key,obs_set in dataset.items():\n",
    "\n",
    "        bst = XGBRegressor();\n",
    "\n",
    "        crf = GridSearchCV(bst, params, refit = True, cv=5, verbose=3) \n",
    "    # fit model\n",
    "        \n",
    "        crf.fit(obs_set['X_train'].astype('float32'), obs_set['y_train'].astype('float32'))\n",
    "\n",
    "        best_model = crf.best_estimator_\n",
    "        XG_boost_models[key]={\"gridsearch\":crf,\"model\":crf,\"score\":crf.score(dataset[key][\"X_test\"].astype('float32'),dataset[key][\"y_test\"].astype('float32')), \"RMSE\":np_RMSE(crf.predict(dataset[key][\"X_test\"].astype('float32')),dataset[key][\"y_test\"].astype('float32').squeeze(), key)}\n",
    "        XG_boost_models[key]['norm_RMSE']=XG_boost_models[key]['RMSE']/(obs_set[\"y_test\"].mean())\n",
    "    return XG_boost_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706dc871-e277-4958-a78c-cddd5ffe0ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LakeEnv",
   "language": "python",
   "name": "lakeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
